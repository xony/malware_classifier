#!/usr/bin/env python
# encoding: utf-8
#
# This script will load the previously saved nu and width values and also svm-data and create a model with the help on ocsvm.
# Subsequently this model will be evaluated using cross validation with the help of leave-one-out. Results are saved to file.
#
# Runs only on the previously filtered nu and width values from step 03. This assures we only run cross validation on sane values,
# where the density estimation contains nearly all trained traces.

import numpy as np
import os, json, math
from config import *

from modshogun import LongIntFeatures, RealFeatures, GaussianKernel, LibSVMOneClass

def remap_keys(mapping):
    return [{'key':k, 'value': v} for k, v in mapping.iteritems()]

def unmap_keys(mapping):
    return_dict = {}
    for d in mapping:
        return_dict[tuple(d['key'])]= d['value']
    return return_dict
        

def train_oneclass (train_data,width=2,C=10,epsilon=1e-7, nu=1e-4):

        feat_array = np.transpose(np.array(train_data))
        #print feat_array.shape
        feats_train=LongIntFeatures(feat_array)

        kernel=GaussianKernel(feats_train, feats_train, width)
        svm=LibSVMOneClass(C, kernel)
        #svm.set_epsilon(epsilon)
        svm.set_nu(nu)
        svm.train()
        return svm


def test_oneclass (test_data, svm, width_current):
        # the width is only needed for displaying purposes, the actual value is inside the SVM!        
        feat_array= np.transpose(np.array(test_data))
        #print feat_array.shape
        feats_test=LongIntFeatures(feat_array)
        predictions = svm.apply(feats_test)
        #return predictions, svm, predictions.get_labels()
        negative = 0
        positive = 0
        for i in predictions.get_labels():
            if i > 0:
                positive += 1
            else:
                negative += 1
        percentage = float(positive) / float(negative+positive)
        print "nu", svm.get_nu(), "width", width_current,"supv",svm.get_num_support_vectors(),"positive", positive, "negative", negative, "percentage positive:", percentage 
        raw_predictions = predictions.get_labels()
        return raw_predictions

def dict_to_list (leave_out, current_dict):
        l = [] # the list to give back
        for item in current_dict:
            if item not in leave_out:
                l.extend(current_dict[item])
        return l

def validate (nu_current, width_current, result_dict, mal_traces_dict, ben_traces_dict):
    # do the evaluation for binary / frq
    left_out_dict = {}
    left_out_dict["nu"] = nu_current
    left_out_dict["width"] = width_current
    testing_results = {}

    # train the classifier on the benign data
    ben_list = dict_to_list([], ben_traces_dict)
    svm = train_oneclass(ben_list, width=width_current, nu=nu_current)
    for item in mal_traces_dict:

        # test on the left out app, but only if it is not empty
        if mal_traces_dict[item] == []:
            continue
        testing_results[item] = test_oneclass(mal_traces_dict[item], svm, width_current).tolist()

    left_out_dict["results"] = testing_results

    # save the results for binary
    result_dict[(nu_current,width_current)] = left_out_dict


if __name__ == '__main__':

    # load all the saved parameters with the low false positive rates 
    print "Loading previously saved params with low trained fp values..."
    with open(RESULT_DIRECTORY + "/" + "binary_results.json", 'r') as infile:
        bin_low_fp = unmap_keys(json.load(infile))
    with open(RESULT_DIRECTORY + "/" + "frequency_results.json", 'r') as infile:
        frq_low_fp = unmap_keys(json.load(infile))
    

    print "Calculating untrained FP percentage..."

    def get_pct(d):
        res_d = {}
        for (nu, width), v in d.iteritems():
            res = v["results"]
            total = 0
            positive = 0
            for classified in res.itervalues():
                total += 1
                if classified > 0:
                    positive += 1
            pct_pos = float(positive) / total
            res_d[(nu,width)] = pct_pos
        return res_d

    bin_pcts = get_pct(bin_low_fp)
    frq_pcts = get_pct(frq_low_fp)


    print "Checking low fp binary params against malware traces"


    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_benign = json.load(infile)
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_benign = json.load(infile)

    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_malicous = json.load(infile)
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_malicous = json.load(infile)


    bin_results = {}
    frq_results = {}
    for nu, width in bin_pcts.keys():
        validate(nu, width, bin_results, bin_dict_malicous, bin_dict_benign)

    for nu, width in frq_pcts.keys():
        validate(nu, width, frq_results, frq_dict_malicous, frq_dict_benign)

    
    # add the pcts to the results
    for k in bin_results.keys():
        bin_results[k]["positive_rate"] = bin_pcts[k]
    
    for k in frq_results.keys():
        frq_results[k]["positive_rate"] = frq_pcts[k]


            
    # write it out to file 
    with open(RESULT_DIRECTORY + "/" + 'mal_binary_results.json', 'w') as outfile:
        json.dump(remap_keys(bin_results), outfile, indent=2)
    with open(RESULT_DIRECTORY + "/" + 'mal_frequency_results.json', 'w') as outfile:
        json.dump(remap_keys(frq_results), outfile, indent=2)
