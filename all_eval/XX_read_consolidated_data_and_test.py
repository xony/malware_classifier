#!/usr/bin/env python
# encoding: utf-8
#
#
# This script will load the data from svmdata and test multiple one-class settings:
# 
# output will be a dict of dict of dicts: {ID1: { (param1, param2) : result, ...}, ...}
#       with ID1 being 001,002,... the manual mapping between good and bad apps
#           
#   result will have following attributes:
#       * num_sv
#       * correct_goodware
#       * correct_malware
#       * results {'mal':[..], 'ben':[..]}
#
# will be done for multiple kernels:
# -> linear kernel
#   * use one-class grid search on \nu to determine results
#
# -> rbf kernel
#   * use grid search on \nu and width to determine results
#
# -> string kernel
#   * use grid search on \nu to determine results 


 
import numpy as np
import time, os, json, math
from config import *

from modshogun import LongIntFeatures, RealFeatures, GaussianKernel, LibSVMOneClass, LinearKernel

NFOLD = 3

# {{{ helper
def accumulate(curr_res):
    res = []
    for v in curr_res.itervalues():
        res.extend(v['mal'])
    return res 

def calculate_correct_goodware(somelist):
    count = 0
    for item in somelist:
        if item == +1:
            count += 1
    return float(count) / len(somelist)

def portion_vectors(vectors, numfolds):
    num_vectors = len(vectors)
    result_dict = {}

    for i in range(numfolds):
        result_dict[i]=[]

    count = 0
    for v in vectors:
        result_dict[count % numfolds].append(v)
        count += 1

    return result_dict
        

def unicode_to_ascii(ustringv):
    # convert unicode tring to ascii
    astringv = []
    for ustring in ustringv:
        astringv.append(ustring.encode('ascii', 'ignore'))
    return astringv



def get_time_str():
    timestr = time.strftime("%Y%m%d-%H%M%S")
    return timestr

def count_labels(predictions):
    negative = 0
    positive = 0
    for i in predictions.get_labels():
        if i > 0:
            positive += 1
        else:
            negative += 1
    return (positive, negative)

def scale_data(train_unscaled, test_unscaled):
    from sklearn import preprocessing
    min_max_scaler = preprocessing.MinMaxScaler()

    array_train = np.asarray(train_unscaled, dtype=np.float64) 
    array_test = np.asarray(test_unscaled, dtype=np.float64) 

    train_scaled = min_max_scaler.fit_transform(array_train)
    test_scaled = min_max_scaler.transform(array_test)

    return train_scaled, test_scaled


def dict_to_list (leave_out, current_dict):
    l = [] # the list to give back
    for item in current_dict:
        if item not in leave_out:
            for i in current_dict[item]:
                l.append([float(j) for j in i])
            #l.extend([float(i) for i in current_dict[item]])
    return l

def leave_one_out (leave_out, current_dict):
    l = [] # the list to give back
    for item in current_dict:
        if item not in leave_out:
            l.extend(current_dict[item])
    return l

def dict_to_list_string (leave_out, current_dict):
    return leave_one_out(leave_out, current_dict)

def make_string_feature (astringv, start=1, order=8, gap=0, reverse=False):
    from modshogun import StringUlongFeatures, StringCharFeatures, RAWBYTE 
    from modshogun import SortUlongString


    charfeat=StringCharFeatures(astringv, RAWBYTE)

    feats_train=StringUlongFeatures(charfeat.get_alphabet())
    feats_train.obtain_from_char(charfeat, start, order, gap, reverse)
    preproc=SortUlongString()
    preproc.init(feats_train)
    feats_train.add_preprocessor(preproc)
    feats_train.apply_preprocessor()

    return feats_train

def make_combined_feature (astringv, minseq = 3, maxseq = 8):
    from modshogun import CombinedFeatures

    feats_train=CombinedFeatures()
    raw_feats = []
    # initialize the subfeats
    for seqlen in range(minseq, maxseq+1):

        subkfeats_train=make_string_feature(astringv, start=seqlen-1, order=seqlen)
        raw_feats.append(subkfeats_train)
        feats_train.append_feature_obj(subkfeats_train)

    return feats_train, raw_feats

def make_real_feature(feat_vector):
    feat_array= np.transpose(np.array(feat_vector))
    feats_test=RealFeatures(feat_array)
    
    return feats_test

def make_int_feature(feat_vector):
    feat_array= np.transpose(np.array(feat_vector))
    feats_test=LongIntFeatures(feat_array)
    
    return feats_test 

def make_combined_kernel(feats_train, raw_train, use_sign=True, minseq=3, maxseq=8):
    from modshogun import CombinedKernel
    from modshogun import CommUlongStringKernel

    # init the combined kernel
    kernel=CombinedKernel()

    # initialize the subkernels
    count = 0
    for seqlen in range(minseq, maxseq+1):

        subkernel=CommUlongStringKernel(raw_train[count], raw_train[count], use_sign)
        kernel.append_kernel(subkernel)

        count += 1

    kernel.init(feats_train, feats_train)
    km_train=kernel.get_kernel_matrix()

    return kernel

# }}}

# {{{ train and test vector
def train_oneclass_linear (feats_train, nu=1e-4):
        C = 10 # dummy value, will be overwritten by nu

        kernel=LinearKernel(feats_train, feats_train)
        svm=LibSVMOneClass(C, kernel)
        svm.set_nu(nu)
        svm.train()
        return svm

def train_oneclass_rbf (feats_train,width=2, nu=1e-4):
        C = 10 # dummy value, will be overwritten by nu

        kernel=GaussianKernel(feats_train, feats_train, width)
        svm=LibSVMOneClass(C, kernel)
        svm.set_nu(nu)
        svm.train()
        return svm

def test_oneclass_vector (feats_train, feats_test, svm, width_current=False):
        # the width is only needed for displaying purposes, the actual value is inside the SVM!        

        train_predictions = svm.apply(feats_train)
        test_predictions = svm.apply(feats_test)
        
        cp, fn = count_labels(train_predictions)
        fp, cn = count_labels(test_predictions)        

        correct_goodware = float(cp) / (float(cp) + float(fn))
        correct_malware = float(cn) / (float(cn) + float(fp))

        raw_predictions = {}
        raw_predictions['ben'] = train_predictions.get_labels().tolist()
        raw_predictions['mal'] = test_predictions.get_labels().tolist()
        return (correct_goodware, correct_malware, svm.get_num_support_vectors(), raw_predictions)
# }}}

# {{{ train and test string 
def train_oneclass_string (feats_train, nu=1e-4, simple=True):

        from modshogun import CommUlongStringKernel
        C = 100 # dummy        

        use_sign=simple

        kernel=CommUlongStringKernel(feats_train, feats_train, use_sign)

        km_train=kernel.get_kernel_matrix()

        svm=LibSVMOneClass(C, kernel)

        svm.set_nu(nu)
        svm.train()
        return svm

def test_oneclass_string (feats_train, feats_test, svm):

        train_predictions = svm.apply(feats_train)
        test_predictions = svm.apply(feats_test)
        
        def count_labels(predictions):
            negative = 0
            positive = 0
            for i in predictions.get_labels():
                if i > 0:
                    positive += 1
                else:
                    negative += 1
            return (positive, negative)

        cp, fn = count_labels(train_predictions)
        fp, cn = count_labels(test_predictions)        

        correct_goodware = float(cp) / (float(cp) + float(fn))
        correct_malware = float(cn) / (float(cn) + float(fp))

        #print "nu", svm.get_nu(), "supv",svm.get_num_support_vectors(),"correct train pct", correct_goodware, "correct test pct", correct_malware 

        raw_predictions = {}
        raw_predictions['ben'] = train_predictions.get_labels().tolist()
        raw_predictions['mal'] = test_predictions.get_labels().tolist()
        return (correct_goodware, correct_malware, svm.get_num_support_vectors(), raw_predictions)

# }}}


# {{{ validate_frq
def validate_frq (nu_current, result_dict, traces_dict, linear=True, width=False, scaling=True):
    """ params:
            nu_current
            result_dict with  nu_current : {numsv, correct_goodware, correct_malware, test_results}
            traces_dict with 'mal' and 'ben' as keys
            linear with bool whether linear kernel is used
            width is only applicable is RBF kernel is used (linear=False)
    
        constants:
            NFOLD is the number of cross validations done
    """
    start_time = time.time()
    current_validate_dict = {}

    # {{{ regular training starts here
    benign_vectors = traces_dict['ben'] # this is a vector of vectors
    malware_vectors = traces_dict['mal']# this is a vector of vectors
    
    if scaling:
        benign_vectors, malware_vectors = scale_data(benign_vectors, malware_vectors)

        feats_train = make_real_feature(benign_vectors)
        feats_test  = make_real_feature(malware_vectors)
    else:
        #feats_train = make_int_feature(benign_vectors)
        #feats_test  = make_int_feature(malware_vectors)
        feats_train = make_real_feature(benign_vectors)
        feats_test  = make_real_feature(malware_vectors)


    # calculate how much of the current training data gets recognized as benign just so

    # train on all vectors 

    if linear:
        svm = train_oneclass_linear(feats_train, nu=nu_current)
    else:
        svm = train_oneclass_rbf(feats_train, nu=nu_current, width = width)

    # test on all vectors 
    testing_results = []
    correct_goodware, correct_malware, numsv, testing_results = test_oneclass_vector(feats_train, feats_test, svm, width_current=width)


    # }}} regular training ends here
    

# {{{ cross validating FP rate
    benign_vectors_dict = portion_vectors(traces_dict['ben'], NFOLD)
    print "partitioned into:",len(benign_vectors_dict[0]),len(benign_vectors_dict[1]),len(benign_vectors_dict[2])


    fold_testing_results = {}
    fold_correct_goodware = {}
    fold_correct_provisioned = {}
    fold_numsv = {}
    fold_curr_testing_results = {}
    for i in range(NFOLD):
        benign_vectors = leave_one_out([i],benign_vectors_dict)
        if scaling:
            benign_vectors, provisioned_benign_vectors = scale_data(benign_vectors, benign_vectors_dict[i])

            feats_train = make_real_feature(benign_vectors)
            feats_test  = make_real_feature(provisioned_benign_vectors)
        else:
            #feats_train = make_int_feature(benign_vectors)
            #feats_test  = make_int_feature(benign_vectors_dict[i])
            feats_train = make_real_feature(benign_vectors)
            feats_test  = make_real_feature(benign_vectors_dict[i])


        # calculate how much of the current training data gets recognized as benign just so

        # train on all vectors 

        if linear:
            svm = train_oneclass_linear(feats_train, nu=nu_current)
        else:
            svm = train_oneclass_rbf(feats_train, nu=nu_current, width = width)

        # test on all vectors 
        fold_correct_goodware[i], fold_correct_provisioned[i], fold_numsv[i], fold_curr_testing_results[i] = test_oneclass_vector(feats_train, feats_test, svm, width_current=width)

# }}}
    testing_results['ben'] = accumulate(fold_curr_testing_results)
    current_validate_dict["results"] = testing_results
    current_validate_dict["correct_goodware"] = calculate_correct_goodware(testing_results['ben'])
    current_validate_dict["correct_malware"] = correct_malware
    current_validate_dict["numsv"] = numsv 
    if not linear:
        current_validate_dict['nu'] = nu_current
        current_validate_dict['width'] = width

    end_time = time.time()
    current_validate_dict["elapsed_time"] = end_time - start_time

    if linear:
        print 'LIN nu:', nu_current, " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']
    else:
        print 'RBF nu:', nu_current,' width:',width, " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']

    # save the results in dict that is referenced
    if linear:
        result_dict[nu_current] = current_validate_dict
    else:
        result_dict[ str(nu_current) + ':' + str(width)] = current_validate_dict
# }}}

# {{{ validate_seq
def validate_seq (nu_current, result_dict, traces_dict, simple=True, start=1, order=8):
    """ params:
            nu_current
            result_dict with  nu_current : {numsv, correct_goodware, correct_malware, test_results}
            traces_dict with 'mal' and 'ben' as keys
    
        constants:
            NFOLD is the number of cross validations done
    """
    start_time = time.time()
    current_validate_dict = {}

    benign_strings = traces_dict['ben'] # this is a vector of (unicode) strings
    malware_strings = traces_dict['mal']

# {{{ conventional testing
    feats_train = make_string_feature(unicode_to_ascii(benign_strings), start=start, order=order)
    feats_test  = make_string_feature(unicode_to_ascii(malware_strings), start=start, order=order)


    # calculate how much of the current training data gets recognized as benign just so

    # train on all vectors 
    svm = train_oneclass_string(feats_train, nu=nu_current, simple=simple)

    # test on all vectors 
    testing_results = []
    correct_goodware, correct_malware, numsv, testing_results = test_oneclass_string(feats_train, feats_test, svm)
# }}}

# {{{ cross evaluation
    benign_strings_dict = portion_vectors(traces_dict['ben'], NFOLD)

    fold_testing_results = {}
    fold_correct_goodware = {}
    fold_correct_provisioned = {}
    fold_numsv = {}
    fold_curr_testing_results = {}
    for i in range(NFOLD):
        benign_strings = leave_one_out([i],benign_strings_dict)
        feats_train = make_string_feature(unicode_to_ascii(benign_strings), start=start, order=order)
        feats_test  = make_string_feature(unicode_to_ascii(benign_strings_dict[i]), start=start, order=order)

        svm = train_oneclass_string(feats_train, nu=nu_current, simple=simple)

        fold_correct_goodware[i], fold_correct_provisioned[i], fold_numsv[i], fold_curr_testing_results[i] = test_oneclass_string(feats_train, feats_test, svm)
# }}}

    testing_results['ben'] = accumulate(fold_curr_testing_results)
    current_validate_dict["results"] = testing_results
    current_validate_dict["correct_goodware"] = calculate_correct_goodware(testing_results['ben'])
    current_validate_dict["correct_malware"] = correct_malware
    current_validate_dict["numsv"] = numsv 
    current_validate_dict['start'] = start
    current_validate_dict['order'] = order
    current_validate_dict['nu'] = nu_current
   
    end_time = time.time()
    current_validate_dict["elapsed_time"] = end_time - start_time

    print 'SEQ nu:', nu_current, "order:" , order , " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']

    # save the results in dict that is referenced
    result_dict[str(nu_current) +":"+ str(start) +":"+ str(order)] = current_validate_dict
# }}}

# {{{ evaluate_seq
def evaluate_seq():

    # load all the saved svm data
    seq_data_dict = {}
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "sequence_vectors", 'r') as infile:
        seq_data_dict['ben'] = dict_to_list_string([],json.load(infile))
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "sequence_vectors", 'r') as infile:
        seq_data_dict['mal'] = dict_to_list_string([],json.load(infile))
    
    print "SEQ CLASSIFIER TRAINING", "*" * 16

    seq_results        = {} # target dict
    seq_results_simple = {} # target dict

        
    current_result = {}
    current_result_simple = {}

    #for i in range(0,-15,-1):
    for i in range(50):
         nu = 1 * math.pow(0.8,i)
         #nu = math.pow(2,i)
         
         validate_seq(nu, current_result, seq_data_dict, simple=False)
         validate_seq(nu, current_result_simple, seq_data_dict, simple=True)


    timestr = get_time_str()
    with open( RESULT_DIRECTORY + '/' +'seq_evaluation_all_simple' +timestr + '.json', 'w') as outfile:
        json.dump(current_result_simple, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'seq_evaluation_all' + timestr +'.json', 'w') as outfile:
        json.dump(current_result, outfile, indent=2)
# }}} 

# {{{ evaluate_frq
def evaluate_frq():

    # load all the saved svm data
    frq_data_dict = {}
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_data_dict['ben'] = dict_to_list([],json.load(infile))
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_data_dict['mal'] = dict_to_list([],json.load(infile))
    

    print "FRQ CLASSIFIER TRAINING", "*" * 16

    frq_results         = {} # target dict
    frq_results_linear  = {} # target dict

        
    current_result = {}
    current_result_linear = {}
    for i in range(100):
         nu = 1 * math.pow(0.9,i)
         
         validate_frq(nu, current_result_linear, frq_data_dict, linear=True)

    for j in range(3,-15,-2):
        for i in range(50):
            nu = 1 * math.pow(0.8,i)
            width = math.pow(2,j)
            
            validate_frq(nu, current_result, frq_data_dict, linear=False, width=width)


    frq_results = current_result
    frq_results_linear = current_result_linear

     
    timestr = get_time_str()
    with open( RESULT_DIRECTORY + '/' +'frq_evaluation_all' + timestr +'.json', 'w') as outfile:
        json.dump(frq_results, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'frq_evaluation_all_linear' + timestr +'.json', 'w') as outfile:
        json.dump(frq_results_linear, outfile, indent=2)
# }}}

# {{{ evaluate_bin
def evaluate_bin():
    # Basically the same as evaluate_frq
    # just input and output files changed. also, no scaling!

    # load all the saved svm data
    frq_data_dict = {}
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        frq_data_dict['ben'] = dict_to_list([],json.load(infile))
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        frq_data_dict['mal'] = dict_to_list([],json.load(infile))
    

    print "FRQ CLASSIFIER TRAINING", "*" * 16

    frq_results         = {} # target dict
    frq_results_linear  = {} # target dict

        
    current_result = {}
    current_result_linear = {}
    for i in range(100):
         nu = 1 * math.pow(0.9,i)
         
         validate_frq(nu, current_result_linear, frq_data_dict, linear=True, scaling=False)

    for j in range(3,-15,-2):
        for i in range(50):
            nu = 1 * math.pow(0.8,i)
            width = math.pow(2,j)
            
            validate_frq(nu, current_result, frq_data_dict, linear=False, width=width, scaling=False)


    frq_results = current_result
    frq_results_linear = current_result_linear

     
    timestr = get_time_str()
    with open( RESULT_DIRECTORY + '/' +'bin_evaluation_all' + timestr +'.json', 'w') as outfile:
        json.dump(frq_results, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'bin_evaluation_all_linear' + timestr +'.json', 'w') as outfile:
        json.dump(frq_results_linear, outfile, indent=2)# }}}

if __name__ == '__main__':


    # load all the saved svm data
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_benign = json.load(infile)
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_malicous = json.load(infile)

    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_benign = json.load(infile)
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_malicous = json.load(infile)
   

    #
    # choose YOUR eval!
    #

    #evaluate_seq()
    #evaluate_frq()
    evaluate_bin()
