#!/usr/bin/env python
# encoding: utf-8
#
# This script will load the previously saved nu and width values and also svm-data and create a model with the help on ocsvm.
# Subsequently this model will be evaluated using cross validation with the help of leave-one-out. Results are saved to file.
#
# Runs only on the previously filtered nu and width values from step 03. This assures we only run cross validation on sane values,
# where the density estimation contains nearly all trained traces.

import numpy as np
import os, json, math
from config import *

from modshogun import LongIntFeatures, RealFeatures, GaussianKernel, LibSVMOneClass

def remap_keys(mapping):
    return [{'key':k, 'value': v} for k, v in mapping.iteritems()]

def read_candidate_values(positive_threshold):
    with open('candidates.json', 'r') as infile:
        inlist = json.load(infile)
        # format: bin_all_nu, bin_all_width, bin_all_pos, freq_all_pos

        # now check the positive (1-fp) values of binary classification...
        bin_candidates = {}
        for i in range(len(inlist[2])):
            value = inlist[2][i]
            if value >= positive_threshold:
                nu = inlist[0][i]
                width = inlist[1][i]
                bin_candidates[(nu,width)] = value

        # now check the positive (1-fp) values of frequency classification...
        frq_candidates = {}
        for i in range(len(inlist[3])):
            value = inlist[3][i]
            if value >= positive_threshold:
                nu = inlist[0][i]
                width = inlist[1][i]
                frq_candidates[(nu,width)] = value

        with open('selected_candidates_bin.json', 'w') as outfile:
            json.dump(remap_keys(bin_candidates), outfile, indent=2)

        with open('selected_candidates_frq.json', 'w') as outfile:
            json.dump(remap_keys(frq_candidates), outfile, indent=2)
        
        return (bin_candidates, frq_candidates)

def read_candidate_values_dict(positive_threshold):
    with open('candidates_bin.json', 'r') as infile:
        bin_candidates_raw = json.load(infile)
        # format: bin_all_nu, bin_all_width, bin_all_pos, freq_all_pos

    with open('candidates_frq.json', 'r') as infile:
        frq_candidates_raw = json.load(infile)

    # now check the positive (1-fp) values of binary classification...
    bin_candidates = {}
    for value_dict in bin_candidates_raw.values():
        if value_dict["percentage"] >= positive_threshold:
            nu = value_dict["nu"]
            width = value_dict["width"]
            bin_candidates[(nu,width)] = value_dict["percentage"]

    # now check the positive (1-fp) values of frequency classification...
    frq_candidates = {}
    for value_dict in frq_candidates_raw.values():
        if value_dict["percentage"] >= positive_threshold:
            nu = value_dict["nu"]
            width = value_dict["width"]
            frq_candidates[(nu,width)] = value_dict["percentage"]

    with open(RESULT_DIRECTORY + "/" + 'selected_candidates_bin.json', 'w') as outfile:
        json.dump(remap_keys(bin_candidates), outfile, indent=2)

    with open(RESULT_DIRECTORY + "/" +'selected_candidates_frq.json', 'w') as outfile:
        json.dump(remap_keys(frq_candidates), outfile, indent=2)
    
    return (bin_candidates, frq_candidates)



def train_oneclass (train_data,width=2,C=10,epsilon=1e-7, nu=1e-4):

        feat_array = np.transpose(np.array(train_data))
        #print feat_array.shape
        feats_train=LongIntFeatures(feat_array)

        kernel=GaussianKernel(feats_train, feats_train, width)
        svm=LibSVMOneClass(C, kernel)
        #svm.set_epsilon(epsilon)
        svm.set_nu(nu)
        svm.train()
        return svm


def test_oneclass (test_data, svm, width_current):
        # the width is only needed for displaying purposes, the actual value is inside the SVM!        
        feat_array= np.transpose(np.array(test_data))
        #print feat_array.shape
        feats_test=LongIntFeatures(feat_array)
        predictions = svm.apply(feats_test)
        #return predictions, svm, predictions.get_labels()
        negative = 0
        positive = 0
        for i in predictions.get_labels():
            if i > 0:
                positive += 1
            else:
                negative += 1
        percentage = float(positive) / float(negative+positive)
        print "nu", svm.get_nu(), "width", width_current,"supv",svm.get_num_support_vectors(),"positive", positive, "negative", negative, "percentage positive:", percentage 
        raw_predictions = predictions.get_labels()
        return raw_predictions

def dict_to_list (leave_out, current_dict):
        l = [] # the list to give back
        for item in current_dict:
            if item not in leave_out:
                l.extend(current_dict[item])
        return l

def cross_validate (nu_current, width_current, result_dict, traces_dict):
    # do the leave one out cross evaluation for binary
    left_out_dict = {}
    left_out_dict["nu"] = nu_current
    left_out_dict["width"] = width_current
    testing_results = {}
    for item in traces_dict:
        # copy new set without the one vector
        leave_one_out_list = dict_to_list([item], traces_dict)

        # train on all vectors except those by the app
        svm = train_oneclass(leave_one_out_list, width=width_current, nu=nu_current)
        # test on the left out app, but only if it is not empty
        if traces_dict[item] == []:
            continue
        testing_results[item] = test_oneclass(traces_dict[item], svm, width_current).tolist()

    left_out_dict["results"] = testing_results

    # save the results for binary
    result_dict[(nu_current,width_current)] = left_out_dict


if __name__ == '__main__':

    # load all the saved svm data
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "sequence_vectors", 'r') as infile:
        seq_dict_benign = json.load(infile)
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_benign = json.load(infile)
    with open(BENIGN_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_benign = json.load(infile)
    
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "sequence_vectors", 'r') as infile:
        seq_dict_malicous = json.load(infile)
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "frequency_vectors", 'r') as infile:
        frq_dict_malicous = json.load(infile)
    with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + "binary_vectors", 'r') as infile:
        bin_dict_malicous = json.load(infile)
 
    length = len(bin_dict_benign.values()[0][0])
    print "featuredim:", length
    print "number of apps in ben:", len(bin_dict_benign.values())
    print "number of apps in mal:", len(bin_dict_malicous.values())

    print "CLASSIFIER TRAINING", "*" * 16

    print "Finding binary Classifier params.."

    bin_results = {}
    frq_results = {}


    prospective_bin, prospective_frq = read_candidate_values(0.90)

    for nu, width in prospective_bin.keys():
        cross_validate(nu, width, bin_results, bin_dict_benign)

    for nu, width in prospective_frq.keys():
        cross_validate(nu, width, frq_results, frq_dict_benign)


    ## this is the old routine for finding all the stuff without preselection:
    #for j in np.arange(20.1,80,0.5):
    #    for i in range(50):
    #        nu = 1 * math.pow(0.8,i)
    #        width = j
    #        
    #        # do the leave one out cross evaluation for binary
    #        cross_validate(nu, width, bin_results, bin_dict_benign)
    #        cross_validate(nu, width, frq_results, frq_dict_benign)
            
           


    with open(RESULT_DIRECTORY + "/" + 'binary_results.json', 'w') as outfile:
        json.dump(remap_keys(bin_results), outfile, indent=2)
    with open(RESULT_DIRECTORY + "/" + 'frequency_results.json', 'w') as outfile:
        json.dump(remap_keys(frq_results), outfile, indent=2)
