#!/usr/bin/env python
# encoding: utf-8
#
#
# This script will load the data from svmdata and test multiple one-class settings:
# 
# output will be a dict of dict of dicts: {ID1: { (param1, param2) : result, ...}, ...}
#       with ID1 being 001,002,... the manual mapping between good and bad apps
#           
#   result will have following attributes:
#       * num_sv
#       * correct_goodware
#       * correct_malware
#       * results {'mal':[..], 'ben':[..]}
#
# will be done for multiple kernels:
# -> linear kernel
#   * use one-class grid search on \nu to determine results
#
# -> rbf kernel
#   * use grid search on \nu and width to determine results
#
# -> string kernel
#   * use grid search on \nu to determine results 


 
import numpy as np
import sys, time, os, json, math
from config import *

from modshogun import LongIntFeatures, RealFeatures, GaussianKernel, LibSVMOneClass, LinearKernel

NFOLD = 5

# {{{ helper
def accumulate(curr_res):
    res = []
    for v in curr_res.itervalues():
        res.extend(v['mal'])
    return res 

def calculate_correct_goodware(somelist):
    count = 0
    for item in somelist:
        if item == +1:
            count += 1
    return float(count) / len(somelist)

def portion_vectors(vectors, numfolds):
    num_vectors = len(vectors)
    result_dict = {}

    for i in range(numfolds):
        result_dict[i]=[]

    count = 0
    for v in vectors:
        result_dict[count % numfolds].append(v)
        count += 1

    return result_dict
        

def unicode_to_ascii(ustringv):
    # convert unicode tring to ascii
    astringv = []
    for ustring in ustringv:
        astringv.append(ustring.encode('ascii', 'ignore'))
    return astringv



def get_time_str():
    timestr = time.strftime("%Y%m%d-%H%M%S")
    return timestr

def count_labels(predictions):
    negative = 0
    positive = 0
    for i in predictions.get_labels():
        if i > 0:
            positive += 1
        else:
            negative += 1
    return (positive, negative)

def scale_data(train_unscaled, test_unscaled):
    from sklearn import preprocessing
    min_max_scaler = preprocessing.MinMaxScaler()

    array_train = np.asarray(train_unscaled, dtype=np.float64) 
    array_test = np.asarray(test_unscaled, dtype=np.float64) 

    train_scaled = min_max_scaler.fit_transform(array_train)
    test_scaled = min_max_scaler.transform(array_test)

    return train_scaled, test_scaled


def dict_to_list (leave_out, current_dict):
    l = [] # the list to give back
    for item in current_dict:
        if item not in leave_out:
            for i in current_dict[item]:
                l.append([float(j) for j in i])
            #l.extend([float(i) for i in current_dict[item]])
    return l

def leave_one_out (leave_out, current_dict):
    l = [] # the list to give back
    for item in current_dict:
        if item not in leave_out:
            l.extend(current_dict[item])
    return l

def dict_to_list_string (leave_out, current_dict):
    return leave_one_out(leave_out, current_dict)

def make_string_feature (astringv, start=1, order=8, gap=0, reverse=False):
    from modshogun import StringUlongFeatures, StringCharFeatures, RAWBYTE 
    from modshogun import SortUlongString


    charfeat=StringCharFeatures(astringv, RAWBYTE)

    feats_train=StringUlongFeatures(charfeat.get_alphabet())
    feats_train.obtain_from_char(charfeat, start, order, gap, reverse)
    preproc=SortUlongString()
    preproc.init(feats_train)
    feats_train.add_preprocessor(preproc)
    feats_train.apply_preprocessor()

    return feats_train

def make_combined_feature (astringv, minseq = 3, maxseq = 8):
    from modshogun import CombinedFeatures

    feats_train=CombinedFeatures()
    raw_feats = []
    # initialize the subfeats
    for seqlen in range(minseq, maxseq+1):

        subkfeats_train=make_string_feature(astringv, start=seqlen-1, order=seqlen)
        raw_feats.append(subkfeats_train)
        feats_train.append_feature_obj(subkfeats_train)

    return feats_train, raw_feats

def make_real_feature(feat_vector):
    feat_array= np.transpose(np.array(feat_vector))
    feats_test=RealFeatures(feat_array)
    
    return feats_test

def make_int_feature(feat_vector):
    feat_array= np.transpose(np.array(feat_vector))
    feats_test=LongIntFeatures(feat_array)
    
    return feats_test 

def make_combined_kernel(feats_train, raw_train, use_sign=True, minseq=3, maxseq=8):
    from modshogun import CombinedKernel
    from modshogun import CommUlongStringKernel

    # init the combined kernel
    kernel=CombinedKernel()

    # initialize the subkernels
    count = 0
    for seqlen in range(minseq, maxseq+1):

        subkernel=CommUlongStringKernel(raw_train[count], raw_train[count], use_sign)
        kernel.append_kernel(subkernel)

        count += 1

    kernel.init(feats_train, feats_train)
    km_train=kernel.get_kernel_matrix()

    return kernel

# }}}

# {{{ train and test vector
def train_oneclass_linear (feats_train, nu=1e-4):
        C = 10 # dummy value, will be overwritten by nu

        kernel=LinearKernel(feats_train, feats_train)
        svm=LibSVMOneClass(C, kernel)
        svm.set_nu(nu)
        svm.train()
        return svm

def train_oneclass_rbf (feats_train,width=2, nu=1e-4):
        C = 10 # dummy value, will be overwritten by nu

        kernel=GaussianKernel(feats_train, feats_train, width)
        svm=LibSVMOneClass(C, kernel)
        svm.set_nu(nu)
        svm.train()
        return svm

def test_oneclass_vector (feats_train, feats_test, svm, width_current=False):
        # the width is only needed for displaying purposes, the actual value is inside the SVM!        

        train_predictions = svm.apply(feats_train)
        test_predictions = svm.apply(feats_test)
        
        cp, fn = count_labels(train_predictions)
        fp, cn = count_labels(test_predictions)        

        correct_goodware = float(cp) / (float(cp) + float(fn))
        correct_malware = float(cn) / (float(cn) + float(fp))

        raw_predictions = {}
        raw_predictions['ben'] = train_predictions.get_labels().tolist()
        raw_predictions['mal'] = test_predictions.get_labels().tolist()
        return (correct_goodware, correct_malware, svm.get_num_support_vectors(), raw_predictions)
# }}}

# {{{ train and test combined kernel
def train_oneclass_combined(feats_train, raw_train, nu=1e-4, simple=True, minseq=3, maxseq=8):

    # init the combined kernel
    kernel=make_combined_kernel(feats_train, raw_train, use_sign=simple, minseq=minseq, maxseq=maxseq)

    C = 100 # dummy        
    svm=LibSVMOneClass(C, kernel)

    svm.set_nu(nu)
    svm.train()
    return svm

# }}}

# {{{ train and test string 
def train_oneclass_string (feats_train, nu=1e-4, simple=True):

        from modshogun import CommUlongStringKernel
        C = 100 # dummy        

        use_sign=simple

        kernel=CommUlongStringKernel(feats_train, feats_train, use_sign)

        km_train=kernel.get_kernel_matrix()

        svm=LibSVMOneClass(C, kernel)

        svm.set_nu(nu)
        svm.train()
        return svm

def test_oneclass_string (feats_train, feats_test, svm):

        train_predictions = svm.apply(feats_train)
        test_predictions = svm.apply(feats_test)
        
        def count_labels(predictions):
            negative = 0
            positive = 0
            for i in predictions.get_labels():
                if i > 0:
                    positive += 1
                else:
                    negative += 1
            return (positive, negative)

        cp, fn = count_labels(train_predictions)
        fp, cn = count_labels(test_predictions)        

        correct_goodware = float(cp) / (float(cp) + float(fn))
        correct_malware = float(cn) / (float(cn) + float(fp))

        #print "nu", svm.get_nu(), "supv",svm.get_num_support_vectors(),"correct train pct", correct_goodware, "correct test pct", correct_malware 

        raw_predictions = {}
        raw_predictions['ben'] = train_predictions.get_labels().tolist()
        raw_predictions['mal'] = test_predictions.get_labels().tolist()
        return (correct_goodware, correct_malware, svm.get_num_support_vectors(), raw_predictions)

# }}}


# {{{ validate_frq
def validate_frq (nu_current, result_dict, traces_dict, linear=True, width=False, scaling=True):
    """ params:
            nu_current
            result_dict with  nu_current : {numsv, correct_goodware, correct_malware, test_results}
            traces_dict with 'mal' and 'ben' as keys
            linear with bool whether linear kernel is used
            width is only applicable is RBF kernel is used (linear=False)
    
        constants:
            NFOLD is the number of cross validations done
    """
    start_time = time.time()
    current_validate_dict = {}

    # {{{ regular training starts here
    benign_vectors = traces_dict['ben'] # this is a vector of vectors
    malware_vectors = traces_dict['mal']# this is a vector of vectors
    
    if scaling:
        benign_vectors, malware_vectors = scale_data(benign_vectors, malware_vectors)

        feats_train = make_real_feature(benign_vectors)
        feats_test  = make_real_feature(malware_vectors)
    else:
        feats_train = make_int_feature(benign_vectors)
        feats_test  = make_int_feature(malware_vectors)


    # calculate how much of the current training data gets recognized as benign just so

    # train on all vectors 

    if linear:
        svm = train_oneclass_linear(feats_train, nu=nu_current)
    else:
        svm = train_oneclass_rbf(feats_train, nu=nu_current, width = width)

    # test on all vectors 
    testing_results = []
    correct_goodware, correct_malware, numsv, testing_results = test_oneclass_vector(feats_train, feats_test, svm, width_current=width)


    # }}} regular training ends here
    

# {{{ cross validating FP rate
    benign_vectors_dict = portion_vectors(traces_dict['ben'], NFOLD)
    print "partitioned into:",len(benign_vectors_dict[0]),len(benign_vectors_dict[1]),len(benign_vectors_dict[2]),len(benign_vectors_dict[3]),len(benign_vectors_dict[4])


    fold_testing_results = {}
    fold_correct_goodware = {}
    fold_correct_provisioned = {}
    fold_numsv = {}
    fold_curr_testing_results = {}
    for i in range(NFOLD):
        benign_vectors = leave_one_out([i],benign_vectors_dict)
        if scaling:
            benign_vectors, provisioned_benign_vectors = scale_data(benign_vectors, benign_vectors_dict[i])

            feats_train = make_real_feature(benign_vectors)
            feats_test  = make_real_feature(provisioned_benign_vectors)
        else:
            feats_train = make_int_feature(benign_vectors)
            feats_test  = make_int_feature(benign_vectors_dict[i])


        # calculate how much of the current training data gets recognized as benign just so

        # train on all vectors 

        if linear:
            svm = train_oneclass_linear(feats_train, nu=nu_current)
        else:
            svm = train_oneclass_rbf(feats_train, nu=nu_current, width = width)

        # test on all vectors 
        fold_correct_goodware[i], fold_correct_provisioned[i], fold_numsv[i], fold_curr_testing_results[i] = test_oneclass_vector(feats_train, feats_test, svm, width_current=width)

# }}}
    testing_results['ben'] = accumulate(fold_curr_testing_results)
    current_validate_dict["results"] = testing_results
    current_validate_dict["correct_goodware"] = calculate_correct_goodware(testing_results['ben'])
    current_validate_dict["correct_malware"] = correct_malware
    current_validate_dict["numsv"] = numsv 
    if not linear:
        current_validate_dict['nu'] = nu_current
        current_validate_dict['width'] = width

    end_time = time.time()
    current_validate_dict["elapsed_time"] = end_time - start_time

    if linear:
        print 'LIN nu:', nu_current, " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']
    else:
        print 'RBF nu:', nu_current,' width:',width, " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']

    # save the results in dict that is referenced
    if linear:
        result_dict[nu_current] = current_validate_dict
    else:
        result_dict[ str(nu_current) + ':' + str(width)] = current_validate_dict
# }}}

# {{{ validate_seq
def validate_seq (nu_current, result_dict, traces_dict, simple=True, start=1, order=8):
    """ params:
            nu_current
            result_dict with  nu_current : {numsv, correct_goodware, correct_malware, test_results}
            traces_dict with 'mal' and 'ben' as keys
    
        constants:
            NFOLD is the number of cross validations done
    """
    start_time = time.time()
    current_validate_dict = {}

    benign_strings = traces_dict['ben'] # this is a vector of (unicode) strings
    malware_strings = traces_dict['mal']

# {{{ conventional testing
    feats_train = make_string_feature(unicode_to_ascii(benign_strings), start=start, order=order)
    feats_test  = make_string_feature(unicode_to_ascii(malware_strings), start=start, order=order)


    # calculate how much of the current training data gets recognized as benign just so

    # train on all vectors 
    svm = train_oneclass_string(feats_train, nu=nu_current, simple=simple)

    # test on all vectors 
    testing_results = []
    correct_goodware, correct_malware, numsv, testing_results = test_oneclass_string(feats_train, feats_test, svm)
# }}}

# {{{ cross evaluation
    benign_strings_dict = portion_vectors(traces_dict['ben'], NFOLD)

    fold_testing_results = {}
    fold_correct_goodware = {}
    fold_correct_provisioned = {}
    fold_numsv = {}
    fold_curr_testing_results = {}
    for i in range(NFOLD):
        benign_strings = leave_one_out([i],benign_strings_dict)
        feats_train = make_string_feature(unicode_to_ascii(benign_strings), start=start, order=order)
        feats_test  = make_string_feature(unicode_to_ascii(benign_strings_dict[i]), start=start, order=order)

        svm = train_oneclass_string(feats_train, nu=nu_current, simple=simple)

        fold_correct_goodware[i], fold_correct_provisioned[i], fold_numsv[i], fold_curr_testing_results[i] = test_oneclass_string(feats_train, feats_test, svm)
# }}}

    testing_results['ben'] = accumulate(fold_curr_testing_results)
    current_validate_dict["results"] = testing_results
    current_validate_dict["correct_goodware"] = calculate_correct_goodware(testing_results['ben'])
    current_validate_dict["correct_malware"] = correct_malware
    current_validate_dict["numsv"] = numsv 
    current_validate_dict['start'] = start
    current_validate_dict['order'] = order
    current_validate_dict['nu'] = nu_current
   
    end_time = time.time()
    current_validate_dict["elapsed_time"] = end_time - start_time

    print 'SEQ nu:', nu_current, "order:" , order , " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']

    # save the results in dict that is referenced
    result_dict[str(nu_current) +":"+ str(start) +":"+ str(order)] = current_validate_dict
# }}}

# {{{ validate_seq_combined
def validate_seq_combined (nu_current, result_dict, traces_dict, simple=True, minseq=3, maxseq=8):
    """ params:
            nu_current
            result_dict with  nu_current : {numsv, correct_goodware, correct_malware, test_results}
            traces_dict with 'mal' and 'ben' as keys
    
        constants:
            NFOLD is the number of cross validations done
    """
    start_time = time.time()
    current_validate_dict = {}

# {{{ conventional testing
    benign_strings = traces_dict['ben'] # this is a vector of (unicode) strings
    malware_strings = traces_dict['mal']

    feats_train, raw_train = make_combined_feature(unicode_to_ascii(benign_strings), minseq=minseq, maxseq=maxseq)
    feats_test, raw_test  = make_combined_feature(unicode_to_ascii(malware_strings), minseq=minseq, maxseq=maxseq)

    # calculate how much of the current training data gets recognized as benign just so

    # train on all vectors 
    svm = train_oneclass_combined(feats_train, raw_train, nu=nu_current, simple=simple, minseq=minseq, maxseq=maxseq)

    # test on all vectors 
    testing_results = []
    correct_goodware, correct_malware, numsv, testing_results = test_oneclass_string(feats_train, feats_test, svm)
# }}}

# {{{ cross evaluation
    benign_strings_dict = portion_vectors(traces_dict['ben'], NFOLD)

    fold_testing_results = {}
    fold_correct_goodware = {}
    fold_correct_provisioned = {}
    fold_numsv = {}
    fold_curr_testing_results = {}
    for i in range(NFOLD):
        benign_strings = leave_one_out([i],benign_strings_dict)
        feats_train, raw_train = make_combined_feature(unicode_to_ascii(benign_strings))
        feats_test, raw_train  = make_combined_feature(unicode_to_ascii(benign_strings_dict[i]))

        svm = train_oneclass_combined(feats_train, raw_train, nu=nu_current, simple=simple)

        fold_correct_goodware[i], fold_correct_provisioned[i], fold_numsv[i], fold_curr_testing_results[i] = test_oneclass_string(feats_train, feats_test, svm)
# }}}


    testing_results['ben'] = accumulate(fold_curr_testing_results)
    current_validate_dict["results"] = testing_results
    current_validate_dict["correct_goodware"] = calculate_correct_goodware(testing_results['ben'])
    current_validate_dict["correct_malware"] = correct_malware
    current_validate_dict["numsv"] = numsv 
    
    end_time = time.time()
    current_validate_dict["elapsed_time"] = end_time - start_time

    print 'CMB nu:', nu_current, " numsv:", current_validate_dict['numsv'], ' correct_goodware:', current_validate_dict['correct_goodware'], ' correct_malware:', current_validate_dict['correct_malware']


    # save the results in dict that is referenced
    result_dict[nu_current] = current_validate_dict
# }}}

# {{{ evaluate_seq
def evaluate_seq(benign_apps, malicious_apps):

    # load all the saved svm data
    seq_data_dict = {}
    for dirname in benign_apps:
        with open(BENIGN_SVMDATA_DIRECTORY + '/' + dirname + "/" + "sequence_vectors", 'r') as infile:
            seq_data_dict[dirname[0:3]] = {}
            seq_data_dict[dirname[0:3]]['ben'] = json.load(infile)

    for dirname in malicious_apps:
        with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + dirname + '/' + "sequence_vectors", 'r') as infile:
            if dirname[0:3] in seq_data_dict:
                seq_data_dict[dirname[0:3]]['mal'] = json.load(infile)
            else:
                print "WARNING: malicious svmdata dir ", dirname, " has no benign equivalent"

    markfordel = []
    for k,v in seq_data_dict.iteritems():
        if not ('mal' in v and 'ben' in v):
            print "WARNING: number ", k,  " has either mal or ben missing! Deleting..."
            markfordel.append(k)

    for k in markfordel:
        del(seq_data_dict[k])

    ## initially just do this with 001...
    #newdict = {}
    #newdict['001'] = seq_data_dict['001']
    #seq_data_dict = newdict



    print "SEQ CLASSIFIER TRAINING", "*" * 16

    seq_results        = {} # target dict
    seq_results_simple = {} # target dict

    for k in seq_data_dict.iterkeys():
        
        current_result = {}
        current_result_simple = {}
        for i in range(250):
             nu = 1 * math.pow(0.9,i)
             
             validate_seq(nu, current_result, seq_data_dict[k], simple=False)
             validate_seq(nu, current_result_simple, seq_data_dict[k], simple=True)

        seq_results[k] = current_result
        seq_results_simple[k] = current_result_simple

    timestr = get_time_str() 
    with open( RESULT_DIRECTORY + '/' +'seq_evaluation_single_simple'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results_simple, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'seq_evaluation_single'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results, outfile, indent=2)
# }}} 

# {{{ evaluate_seq_varlen
def evaluate_seq_varlen(benign_apps, malicious_apps):

    # load all the saved svm data
    seq_data_dict = {}
    for dirname in benign_apps:
        with open(BENIGN_SVMDATA_DIRECTORY + '/' + dirname + "/" + "sequence_vectors", 'r') as infile:
            seq_data_dict[dirname[0:3]] = {}
            seq_data_dict[dirname[0:3]]['ben'] = json.load(infile)

    for dirname in malicious_apps:
        with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + dirname + '/' + "sequence_vectors", 'r') as infile:
            if dirname[0:3] in seq_data_dict:
                seq_data_dict[dirname[0:3]]['mal'] = json.load(infile)
            else:
                print "WARNING: malicious svmdata dir ", dirname, " has no benign equivalent"

    markfordel = []
    for k,v in seq_data_dict.iteritems():
        if not ('mal' in v and 'ben' in v):
            print "WARNING: number ", k,  " has either mal or ben missing! Deleting..."
            markfordel.append(k)

    for k in markfordel:
        del(seq_data_dict[k])

    ## initially just do this with 001...
    #newdict = {}
    #newdict['001'] = seq_data_dict['001']
    #seq_data_dict = newdict



    print "SEQ CLASSIFIER TRAINING", "*" * 16

    seq_results        = {} # target dict
    seq_results_simple = {} # target dict

    for k in seq_data_dict.iterkeys():
        
        current_result = {}
        current_result_simple = {}
        for varlen in range(2,9):
            for i in range(100):
                 nu = 1 * math.pow(0.8,i)
                 
                 validate_seq(nu, current_result, seq_data_dict[k], simple=False, start=varlen-1, order=varlen)
                 validate_seq(nu, current_result_simple, seq_data_dict[k], simple=True, start=varlen-1, order=varlen)

            seq_results[k] = current_result
            seq_results_simple[k] = current_result_simple

    timestr = get_time_str() 
    with open( RESULT_DIRECTORY + '/' +'seq_varlen_evaluation_single_simple'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results_simple, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'seq_varlen_evaluation_single'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results, outfile, indent=2)
# }}} 

# {{{ evaluate_cmb
def evaluate_cmb(benign_apps, malicious_apps):

    # load all the saved svm data
    seq_data_dict = {}
    for dirname in benign_apps:
        with open(BENIGN_SVMDATA_DIRECTORY + '/' + dirname + "/" + "sequence_vectors", 'r') as infile:
            seq_data_dict[dirname[0:3]] = {}
            seq_data_dict[dirname[0:3]]['ben'] = json.load(infile)

    for dirname in malicious_apps:
        with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + dirname + '/' + "sequence_vectors", 'r') as infile:
            if dirname[0:3] in seq_data_dict:
                seq_data_dict[dirname[0:3]]['mal'] = json.load(infile)
            else:
                print "WARNING: malicious svmdata dir ", dirname, " has no benign equivalent"

    markfordel = []
    for k,v in seq_data_dict.iteritems():
        if not ('mal' in v and 'ben' in v):
            print "WARNING: number ", k,  " has either mal or ben missing! Deleting..."
            markfordel.append(k)

    for k in markfordel:
        del(seq_data_dict[k])

    ## initially just do this with 001...
    #newdict = {}
    #newdict['001'] = seq_data_dict['001']
    #seq_data_dict = newdict



    print "COMBINED SEQ CLASSIFIER TRAINING", "*" * 16

    seq_results        = {} # target dict
    seq_results_simple = {} # target dict

    for k in seq_data_dict.iterkeys():
        
        current_result = {}
        current_result_simple = {}
        for i in range(100):
             nu = 1 * math.pow(0.9,i)
             
             validate_seq_combined(nu, current_result, seq_data_dict[k], simple=False)
             validate_seq_combined(nu, current_result_simple, seq_data_dict[k], simple=True)

        seq_results[k] = current_result
        seq_results_simple[k] = current_result_simple

    timestr = get_time_str() 
    with open( RESULT_DIRECTORY + '/' +'cmb_evaluation_single_simple'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results_simple, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'cmb_evaluation_single'+ timestr +'.json', 'w') as outfile:
        json.dump(seq_results, outfile, indent=2)
# }}} 

# {{{ evaluate_frq
def evaluate_frq(benign_apps, malicious_apps):

    # load all the saved svm data
    frq_data_dict = {}
    for dirname in benign_apps:
        with open(BENIGN_SVMDATA_DIRECTORY + '/' + dirname + "/" + "frequency_vectors", 'r') as infile:
            frq_data_dict[dirname[0:3]] = {}
            frq_data_dict[dirname[0:3]]['ben'] = json.load(infile)

    for dirname in malicious_apps:
        with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + dirname + '/' + "frequency_vectors", 'r') as infile:
            if dirname[0:3] in frq_data_dict:
                frq_data_dict[dirname[0:3]]['mal'] = json.load(infile)
            else:
                print "WARNING: malicious svmdata dir ", dirname, " has no benign equivalent"

    markfordel = []
    for k,v in frq_data_dict.iteritems():
        if not ('mal' in v and 'ben' in v):
            print "WARNING: number ", k,  " has either mal or ben missing! Deleting..."
            markfordel.append(k)

    for k in markfordel:
        del(frq_data_dict[k])

    ## initially just do this with 001...
    #newdict = {}
    #newdict['001'] = frq_data_dict['001']
    #seq_data_dict = newdict


    print "FRQ CLASSIFIER TRAINING", "*" * 16

    frq_results         = {} # target dict
    frq_results_linear  = {} # target dict

    for k in frq_data_dict.iterkeys():
        
        current_result = {}
        current_result_linear = {}
        for i in range(100):
             nu = 1 * math.pow(0.9,i)
             
             validate_frq(nu, current_result_linear, frq_data_dict[k], linear=True)

        for j in range(3,-15,-2):
            for i in range(50):
                nu = 1 * math.pow(0.8,i)
                width = math.pow(2,j)
                
                validate_frq(nu, current_result, frq_data_dict[k], linear=False, width=width)


        frq_results[k] = current_result
        frq_results_linear[k] = current_result_linear

     
    timestr = get_time_str() 
    with open( RESULT_DIRECTORY + '/' +'frq_evaluation_single'+timestr+'.json', 'w') as outfile:
        json.dump(frq_results, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'frq_evaluation_single_linear'+timestr+'.json', 'w') as outfile:
        json.dump(frq_results_linear, outfile, indent=2)
# }}}

# {{{ evaluate_bin
def evaluate_bin(benign_apps, malicious_apps):
    # Basically the same as evaluate_frq
    # just input and output files changed. also, no scaling!

    # load all the saved svm data
    frq_data_dict = {}
    for dirname in benign_apps:
        with open(BENIGN_SVMDATA_DIRECTORY + '/' + dirname + "/" + "binary_vectors", 'r') as infile:
            frq_data_dict[dirname[0:3]] = {}
            frq_data_dict[dirname[0:3]]['ben'] = json.load(infile)

    for dirname in malicious_apps:
        with open(MALICIOUS_SVMDATA_DIRECTORY + "/" + dirname + '/' + "binary_vectors", 'r') as infile:
            if dirname[0:3] in frq_data_dict:
                frq_data_dict[dirname[0:3]]['mal'] = json.load(infile)
            else:
                print "WARNING: malicious svmdata dir ", dirname, " has no benign equivalent"

    markfordel = []
    for k,v in frq_data_dict.iteritems():
        if not ('mal' in v and 'ben' in v):
            print "WARNING: number ", k,  " has either mal or ben missing! Deleting..."
            markfordel.append(k)

    for k in markfordel:
        del(frq_data_dict[k])

    ## initially just do this with 001...
    #newdict = {}
    #newdict['001'] = frq_data_dict['001']
    #seq_data_dict = newdict


    print "BIN CLASSIFIER TRAINING", "*" * 16

    frq_results         = {} # target dict
    frq_results_linear  = {} # target dict

    for k in frq_data_dict.iterkeys():
        
        current_result = {}
        current_result_linear = {}
        for i in range(100):
             nu = 1 * math.pow(0.9,i)
             
             validate_frq(nu, current_result_linear, frq_data_dict[k], linear=True, scaling=False)

        for j in range(3,-15,-2):
            for i in range(50):
                nu = 1 * math.pow(0.8,i)
                width = math.pow(2,j)
                
                validate_frq(nu, current_result, frq_data_dict[k], linear=False, width=width, scaling=False)


        frq_results[k] = current_result
        frq_results_linear[k] = current_result_linear

     
    timestr = get_time_str() 
    with open( RESULT_DIRECTORY + '/' +'bin_evaluation_single'+timestr+'.json', 'w') as outfile:
        json.dump(frq_results, outfile, indent=2)

    with open( RESULT_DIRECTORY + '/' +'bin_evaluation_single_linear'+timestr+'.json', 'w') as outfile:
        json.dump(frq_results_linear, outfile, indent=2)# }}}

if __name__ == '__main__':


    # we have benign / malicious traces each in their dir.
    # apps that belong together start with the same three digit identifier
    benign_apps     = [] 
    malicious_apps  = [] 

    for dirname in os.listdir(BENIGN_SVMDATA_DIRECTORY):
        if not "_vectors" in dirname:
            benign_apps.append(dirname)

    for dirname in os.listdir(MALICIOUS_SVMDATA_DIRECTORY):
        if not "_vectors" in dirname:
            malicious_apps.append(dirname)



    #
    # choose YOUR eval!
    #

    #evaluate_seq(benign_apps, malicious_apps)
    #evaluate_seq_varlen(benign_apps, malicious_apps)
    #evaluate_frq(benign_apps, malicious_apps)
    #evaluate_bin(benign_apps, malicious_apps)
    evaluate_cmb(benign_apps, malicious_apps)
